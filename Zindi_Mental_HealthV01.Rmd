---
title: 'Zindi_Mental Health Prediction Challenge'
author: "Denis Munene"
date: ' `r as.Date(Sys.time())` '
output:
  pdf_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, fig.width = 10, fig.height = 10)

```


# Introduction

The World Health Organization estimates that 1.3 million Kenyans suffer from untreated major depressive disorder (MDD; commonly known as depression) every year, and that sub-Saharan Africa has the highest prevalence of the illness of any region in the world. Yet mental health treatment in Kenya suffers from a lack of resources and stigmatization. There are only two certified psychiatrists per million people in Kenya. Few facilities exist outside of urban areas and people are unlikely to know about or access them.

Can machine learning help alleviate this problem? Smart targeting of potential cases could help enable scarce resources to reach those who most need it and improve or save an untold number of lives.

With this in mind, the Busara Center for Behavioral Economics decided to challenge the data science community in Nairobi, across Africa, and around the world to predict depression cases from routine survey data. 

# Data Processing

## Importing Libraries

```{r, warning=F }
# load libraries
library(tidyverse)
library(dplyr)
library(mice)
library(VIM)
library(h2o)
library(ggplot2)
```

## Importing Datasets

```{r, warning=F}
# import datasets

# Setting working directory to files' location
setwd("C:/Users/dmunene/OneDrive - Dalberg Global Development Advisors/RESSOL/Personal/Data Analysis/Busara MHPC/Zindi Mental Health/Data")


# read data
d_tr <- read.csv("./train.csv")
d_ts <- read.csv("./test.csv")

```



## Exploring the Datasets

```{r, echo=F}
# Scheming structure of the data variables
str(d_tr)
```

```{r}
# Scheming the top 6 rows (train data)
# head(d_tr)
```


```{r}
# Scheming the top 6 rows (test data)
# head(d_ts)
```

```{r, echo=F}
# Scheming the structure of data variables
str(d_ts)
```


## Data Manipulation

```{r}
# Dropping survey_date and hh_total members on both train and test data
# survey date is not considered important to the study
# hh_total members is a replica of hhsize

d_tr2 <- select(d_tr,-c(3,11))
d_ts2 <- select(d_ts,-c(3,11))

```


```{r}

# Reordering columns in dataset to bring response variable to front
d_tr3 <- d_tr2 %>% select(depressed,everything())
d_ts3 <- d_ts2 %>% select(depressed,everything())
```


```{r}
# Restructuring age as numeric and not factor (testdata)
# ensure response is factor
d_ts3$age <- as.numeric(d_ts3$age)



```

## Data Quality Control

```{r}
# Checking for missingness
colSums(is.na(d_tr3))

# Return the column names containing missing observations
list_na <- colnames(d_tr3)[apply(d_tr3,2,anyNA)]
list_na
```


### Visualizing Missingness
```{r}

# md.pattern(d_tr3)

missingness_plot <- aggr(d_tr3,col = c('navyblue','yellow'),
                  numbers = TRUE,sortVars = TRUE,labels = names(d_tr3),cex.axis = 5,
                  gap = 4,ylab = c("Missing Data ", "Pattern"))

```



### Treating for Missingness
```{r,echo=F,results = "hide" }
# threshold improves the imputation

imputedDT <- mice(d_tr3, m = 5, maxit = 30, method = "cart", seed = 124,threshold = 1)
# summary(imputedDT)

```

### Assessing if missingness is treated
```{r}
# Randomly selecting a sample
completeDT <- complete(imputedDT,3)
colSums(is.na(completeDT))
# Assessing treatment of missing 
listna2 <- colnames(completeDT)[apply(completeDT,2,anyNA)]
listna2
```

### Checking for duplicates

```{r}
obs <- data.frame(table(d_tr3$surveyid))
obs[obs$Freq>1,]

```



## Exploration of Demographic Variables

```{r}
d <- ggplot(completeDT,aes(depressed))
d+geom_bar(aes(y = (..count..)/sum(..count..)))+scale_y_continuous(labels = scales::percent)+theme_minimal()+ylab("Percent")
```


```{r}
a <- ggplot(completeDT,aes(age))+theme_bw()+facet_wrap(~depressed)
a+geom_density()
```


```{r, warning=F}
# age
plot1 <- hist(completeDT$age,breaks = 12,col = "red",xlab = "Respondent Age",main = "Histogram of Age")

```

```{r}
plot1a <- ggplot(completeDT,aes(x = femaleres))+ geom_bar(fill = "red")+labs(title = "Gender",x = "Gender", y = "Frequency")+theme_bw()

print(plot1a)
```


```{r,warning=F}
completeDT$depressed <- as.factor(completeDT$depressed)
e <- ggplot(completeDT,aes(age, fill = depressed))+theme_bw()
e+geom_histogram(binwidth = 10)


```


```{r,warning=F}

plot3 <- ggplot(completeDT, aes(hhsize))+geom_density(fill = "blue")+ labs(title = "Size of household",x = "Size") +theme_bw()

print(plot3)

```


```{r}
completeDT$depressed <- as.factor(completeDT$depressed)
plot3a <- ggplot(completeDT,aes(age,edu,color =depressed, shape = depressed))+stat_smooth() +geom_point(size = 6,alpha = 0.6)

print(plot3a)
```

```{r}
completeDT$depressed <- as.factor(completeDT$depressed)
v <- ggplot(completeDT,aes(age,village, color = depressed, shape = depressed))+stat_smooth()+geom_point(size = 7,alpha = 0.5)

print(v)
```



```{r,warning=F}
plot4 <- ggplot(completeDT, aes(age, as.numeric(depressed)))+stat_smooth(method = "glm",formula = y~x,alpha = 0.2, size = 2)+ geom_point(position = position_jitter(height = 0.3,width = 0))+ xlab("Age")+ylab("Pr (Depressed)")

print(plot4)
```


```{r,warning=F}
plot5 <- ggplot(completeDT, aes(age, as.numeric(depressed), color = as.factor(married)))+stat_smooth(method = "glm",formula = y~x,alpha = 0.2, size = 2)+ geom_point(position = position_jitter(height = 0.3,width = 0))+
  scale_color_discrete("Marital Status",labels = c("Not Married","Married"))+ xlab("Age")+ylab("Pr (Depressed)")

print(plot5)
```


```{r,warning=F}
plot6 <- ggplot(completeDT, aes(edu, as.numeric(depressed), color = as.factor(married)))+stat_smooth(method = "glm",formula = y~x,alpha = 0.2, size = 2)+ geom_point(position = position_jitter(height = 0.3,width = 0))+
  scale_color_discrete("Gender",labels = c("Male","Female"))+ xlab("Years of Education")+ylab("Pr (Depressed)")

print(plot6)
```

```{r}
plot7 <- ggplot(completeDT, aes(edu, as.numeric(depressed), color = as.factor(married)))+stat_smooth(method = "glm",formula = y~x,alpha = 0.2, size = 2)+ geom_point(position = position_jitter(height = 0.3,width = 0))+
  scale_color_discrete("Gender",labels = c("Male","Female"))+ xlab("Years of Education")+ylab("Pr (Depressed)")

print(plot7)
```



## Preparation for MachineLearning

### Variable Aligning

```{r}
## pick a response for the supervised problem
response <- "depressed"

# For binary classification, response should be a factor
completeDT[[response]] <- as.factorcompleteDT[[response]]

## use all other columns (except for the name) as predictors
predictors <- setdiff(names(completeDT),c(response,"name"))
```


### Initializing h2o framework
```{r}
# Working with h2o framework fastens our processes by maximizing comuputer capabilities.
# Link below should help in download and installing before running: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html

h2o.init()
```

### Onboarding datasets on to h2o framework
```{r, results = "hide"}
d_tr4 <- as.h2o(completeDT, destination_frame = "d_tr4")
d_ts4 <- as.h2o(d_ts3, destination_frame = "d_ts4")
```

## Machine Learning

### Test Train Split
```{r, results="hide"}
# Construct test and train sets using sampling whilst maintaining a validation set (usually helps control for overfitting)

tr.split <- h2o.splitFrame(data = d_tr4, ratios = c(0.6,0.2),destination_frames = c("tr.train","tr.valid","tr.test"), seed = 124)
tr.train <- tr.split[[1]]
tr.valid <- tr.split[[2]]
tr.test <- tr.split[[3]]


```

## Modeling

```{r}
## RF

tr.rf <- h2o.randomForest(x = predictors,y = response,training_frame = tr.train, nfolds = 10,fold_assignment = "Modulo", ntrees = 500,keep_cross_validation_predictions = T,seed = 1234)

## Show a detailed model summary
summary(tr.rf)
```


### Assessing Performance

```{r}
print(h2o.auc(h2o.performance(tr.rf,newdata = tr.valid)))
```


```{r}
# confusion matrix from glm model on test data
h2o.confusionMatrix(tr.rf,tr.test)
```


### Predicting


```{r}
# Predict on Main Test data using RF

predicted <- h2o.predict(tr.rf,newdata = d_ts4)
head(predicted)

```


## Output

### Formatting Output
```{r}
predicted_df <- as.data.frame(predicted)

# Embedding on Main test data
df <- data.frame(d_ts$surveyid,predicted_df)
df_f <- df %>% select(surveyid = d_ts.surveyid,depressed = predict)
```


### Submission
```{r}

dir.create("./Output")
write.csv(df_f,"./Output/Submission3e.csv",row.names = F)

```

# Conclusion

Although the study is only a sample representative of the population and limited to the Survey conducted by Busara, the modelling exercise enlightens us about mental health. Beyond the model that can in future be used to predict people likely to be depressed and hence direct health professionals accordinly, it also highlights some of the possible causes of depression. 

Current research on mental health has no sufficient data on clear cut causes of depression, however, using the dataset and modelling we can summarize some variables that seem crucial to determining whether and individual is depressed or not. Top three of these include:

1. Respondent Age
2. Years of Education
3. Village of stay


An indepth study of the variables in relation to mental health is definitely likely to enlighten the stakeholders on measures that would help develop a sustainable solution. 

